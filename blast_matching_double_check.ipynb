{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7c1dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf5b806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/danielcm/Desktop/Sycuro/Projects/Diabetes/t1d_db_fixed_discussed/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40238865",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This section makes a new file (and df) for every barrnap blast output with the necessary headers and adds the number of genus, and species found for every sample individually.\n",
    "#Then, it filters by 98.6 identity or higher, and by e-val of 1e-100\n",
    "master_file = pd.read_csv(\"FINAL_report_WGS_all_csv.csv\")\n",
    "subset_master_file = master_file[['Index','Sample ID','Consortia','Selected for Downstream',\n",
    "                    'Sanger classification (v3v4) Source','Classification species']]\n",
    "input_file_path = path+\"barrnap_blast/\"\n",
    "subset_master_file.set_index('Sample ID',inplace=True)\n",
    "#Manually removed 073 and 100, as they did not have any output in the file except\n",
    "sample_and_species_dict = {}\n",
    "for file in sorted(os.listdir(input_file_path)):\n",
    "    blast_file = pd.read_csv(input_file_path+file,header=None)\n",
    "    blast_file.columns = [\"Sequence ID\",\"Matched ID\",\"Bit score\",\"Score\",\"E-value\",\"% of identity\",\"Sequence\"]\n",
    "    number_of_16S = len(blast_file['Sequence ID'].unique())\n",
    "    blast_file['Number of 16S found'] = number_of_16S\n",
    "    filtered_blast_file = blast_file[(blast_file['% of identity']>=98.6) & (blast_file['E-value']<=1e-100)].copy() #Filtering by e-value and identity\n",
    "    blast_species = filtered_blast_file['Matched ID'].tolist()\n",
    "    matched_species = []\n",
    "    for item in blast_species:\n",
    "        split = item.split(\" \",1)\n",
    "        species_name = split[-1]\n",
    "        matched_species.append(species_name)\n",
    "    filtered_blast_file['Matched species'] = matched_species #All of them that were found at high quality\n",
    "    tmp_id_name = \"_\".join(file.split(\"_\")[3:7]).split(\".\",1)[0] #This assigns just the sample ID without the .csv or the 'prokka_blast' part\n",
    "    filtered_blast_file[\"Sample ID\"] = tmp_id_name\n",
    "    unique_species = filtered_blast_file[\"Matched species\"].unique() #This makes an array (or a list?) of unique species found by BLASTn\n",
    "    genus_list = []\n",
    "    for item in blast_species:\n",
    "        genus = item.split(\" \")[1]\n",
    "        genus_list.append(genus)\n",
    "    sample_and_species_dict[tmp_id_name] = unique_species.tolist()\n",
    "    filtered_blast_file['Matched genus'] = genus_list\n",
    "    unique_genus = filtered_blast_file[\"Matched genus\"].unique() #This makes a list of unique genus found by BLASTn\n",
    "    unique_species = list(unique_species)\n",
    "    unique_genus = list(unique_genus)\n",
    "    filtered_blast_file['Unique species'] = [unique_species]*len(filtered_blast_file)\n",
    "    filtered_blast_file['Unique genus'] = [unique_genus]*len(filtered_blast_file)\n",
    "    filtered_blast_file['No. of unique species'] = len(unique_species)\n",
    "    filtered_blast_file['No. of unique genera'] = len(unique_genus)\n",
    "    filtered_blast_file = filtered_blast_file[['Sample ID','Sequence ID','Matched ID','Bit score','Score','E-value','% of identity','Number of 16S found',\n",
    "                          'Matched species','No. of unique species','Unique species','Matched genus','No. of unique genera','Unique genus','Sequence']]\n",
    "    \n",
    "    filtered_blast_file.to_csv(tmp_id_name+\"blast_filtered.csv\",sep=',') #Sample id as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16f685ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tm/fnbprp5d6gb3vjll_w5r4k3m0000gn/T/ipykernel_83151/97078124.py:29: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  sequences_expanded = df_final['Sequences'].apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "#Confirming match between WGS, 16S v3v4 and BLAST\n",
    "#This script matches the 16S found in the genomes and compares it againts the output of gtdbtk and sanger (v3v4) from Toronto\n",
    "#if it matches gtdbtk, then it is used. If it does not matches gtdbtk, but matches v3v4, then it is also used. Priority is given to \n",
    "#gtdbtk\n",
    "comparison_list=[]\n",
    "fasta_out = open(\"fasta_16S_in_silico.fasta\",\"w\")\n",
    "for sample_id,unique_species in sample_and_species_dict.items():\n",
    "    gtdbtk_species = subset_master_file.loc[sample_id,'Classification species']\n",
    "    sanger_species = subset_master_file.loc[sample_id,'Sanger classification (v3v4) Source']\n",
    "    match1 = gtdbtk_species in unique_species\n",
    "    match2 = sanger_species in unique_species\n",
    "    file_name = sample_id+\"blast_filtered.csv\"\n",
    "    file_to_retrive_sequence = pd.read_csv(path+file_name)\n",
    "    matching_sequence = file_to_retrive_sequence[file_to_retrive_sequence['Matched species'] == gtdbtk_species]['Sequence'].tolist()\n",
    "    if not matching_sequence:\n",
    "        matching_sequence = file_to_retrive_sequence[file_to_retrive_sequence['Matched species']==sanger_species]['Sequence'].tolist()\n",
    "    comparison_list.append({\n",
    "        'Sample ID':sample_id,\n",
    "        'GTDBtk species':gtdbtk_species,\n",
    "        'Sanger species':sanger_species,\n",
    "        'Match blast & gtdbtk?':match1,\n",
    "        'Match blast & sanger?':match2,\n",
    "        'Sequences':matching_sequence\n",
    "    })\n",
    "    for sequence in matching_sequence:\n",
    "        fasta_out.write(\">\"+sample_id+\"\\n\")\n",
    "        fasta_out.write(sequence+\"\\n\")\n",
    "df_final = pd.DataFrame(comparison_list)\n",
    "sequences_expanded = df_final['Sequences'].apply(pd.Series)\n",
    "df_final = df_final.drop('Sequences', axis=1).join(sequences_expanded)\n",
    "df_final.to_csv(\"Final_16S_sequences_from_genomes.csv\")\n",
    "fasta_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section creates the fasta file of the matched sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
